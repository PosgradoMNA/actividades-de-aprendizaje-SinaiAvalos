{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PosgradoMNA/actividades-de-aprendizaje-SinaiAvalos/blob/main/Semana%204/Module1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Sinaí Avalos Rivera*\n",
        "\n",
        "\n",
        "# **Module 1 - Introduction**\n",
        "\n",
        "** THE PROBLEM**\n",
        "\n",
        "\n",
        "** Why Data Analysis?**\n",
        "\n",
        "\n",
        "Data analysis, and in essence, data science, helps us unlock the information and insights\n",
        "from raw data, to answer our questions.\n",
        "\n",
        "So data analysis plays an important role by helping us to discover useful information\n",
        "from the data, answer questions, and even predict the future or the unknown.\n",
        "\n",
        "\n",
        "\n",
        "**Understanding the Data**\n",
        "\n",
        "The value that we want to predict from the dataset, and the predictors should be all the other variables listed.\n",
        "\n",
        "\n",
        "** Python Packages for Data Science**\n",
        "A Python library is a collection of functions and methods that allow you to perform lots\n",
        "of actions without writing any code. \n",
        "\n",
        "\n",
        "The libraries usually contain built-in modules providing different functionalities, which\n",
        "you can use directly.\n",
        "And there are extensive libraries, offering a broad range of facilities.\n",
        "\n",
        "Python data analysis libraries into three groups: The first group is called\n",
        "\"scientific computing libraries.\" Pandas offers data structure and tools for\n",
        "effective data manipulation and analysis.\n",
        "It provides fast access to structured data.\n",
        "\n",
        "The primary instrument of Pandas is a two-dimensional table consisting of column and row labels,\n",
        "which are called a DataFrame.\n",
        "\n",
        "The Numpy library uses arrays for its inputs and outputs. It can be extended to objects for matrices.\n",
        "\n",
        "\n",
        "SciPy includes functions for some advanced math problems, as well as data visualization.\n",
        "\n",
        "Using data visualization methods is the best way to communicate with others, showing them\n",
        "meaningful results of analysis (graphs, charts and maps).\n",
        "\n",
        "The Matplotlib package is the most well-known library for data visualization (graphs and plots).\n",
        "\n",
        "Another high-level visualization library is Seaborn.\n",
        "It's very easy to generate various plots such as heat maps, time series, and violin plots.\n",
        "\n",
        "\n",
        "With Machine Learning algorithms, we're able to develop a model using our dataset,\n",
        "and obtain predictions.\n",
        "The algorithmic libraries tackle some machine learning tasks from basic to complex.\n",
        "\n",
        "Two packages: \n",
        "1. The Scikit-learn library contains tools for\n",
        "statistical modeling, including regression, classification, clustering, etc.\n",
        "\n",
        "2. StatsModels is also a Python module that allows users to explore data, estimate statistical\n",
        "models, and perform statistical tests.\n"
      ],
      "metadata": {
        "id": "2k1NqtYGWthI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing and Exporting Data in Python**\n",
        "\n",
        "\n",
        "Data acquisition is a process of loading and reading data into notebook from various sources.\n",
        "\n",
        "To read any data using Python’s pandas package, there are two important factors to consider:\n",
        "format and file path.\n",
        "\n",
        "Format is the way data is encoded (csv, json, xlsx, hdf, etc.).\n",
        "\n",
        "The (file) path tells us where the data is stored.\n",
        "\n",
        "In pandas, the “read_csv()” method can read in files with columns separated by commas\n",
        "into a pandas DataFrame: \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# import pandas as pd\n",
        "\n",
        "url = \"https.....\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "```\n",
        "\n",
        "However, “read_csv” assumes that the data contains a header.\n",
        "\n",
        "If it has no column headers,  we need to specify “read_csv” to not assign headers by setting header to “none”.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# df = pd.read_csv(url, header = None)\n",
        "\n",
        "```\n",
        "\n",
        "df -> prints the entire dataframe\n",
        "\n",
        "df.head(n) -> to show the first n rows of the data frame. \n",
        "\n",
        "dataframe.tail(n) -> shows the bottom n rows of data frame\n",
        "\n",
        "We can assign column names in pandas:\n",
        "\n",
        "```\n",
        "headers = [\"title1\", \"title2\", ...]\n",
        "# df.columns = headers\n",
        "\n",
        "```\n",
        "\n",
        "to export your pandas dataframe to a new CSV file.\n",
        "You can do this using the method, ”to_csv()\"\n",
        "To do this, specify the file path that you want to write to.\n",
        "\n",
        "\n",
        "```\n",
        "path=\"C:\\Windows\\....\\automobile.csv\"\n",
        "df.to_csv(path)\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "c5ohjZzKymbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting Started Analyzing Data in Python**\n",
        "\n",
        "Pandas has several built in methods that could be used to understand the datatype of\n",
        "features or to look at the distribution of data within the dataset.\n",
        "\n",
        "\n",
        "Data has a variety of types.\n",
        "The main types stored in Pandas objects are object, float, int, and datetime.\n",
        "\n",
        "\n",
        "There are two reasons to check data types in a dataset.\n",
        "Pandas automatically assigns types based on the encoding it detects from the original\n",
        "data table.\n",
        "For a number of reasons, this assignment may be incorrect.\n",
        "\n",
        "\n",
        "The second reason is that it allows an experienced data scientist to see which Python functions\n",
        "can be applied to a specific column.\n",
        "\n",
        "df.dtypes -> the datatype of each column\n",
        "is returned in a Series\n",
        "\n",
        "\n",
        "\n",
        "To check the statistical summary of each column to learn about the distribution of data in each column:\n",
        "\n",
        "df.describe() -> It returns the number of terms in the column as \"count\", average column value as \"mean\",\n",
        "column standard deviation as \"std\", the maximum and minimum values, as well as the boundary of each of the quartiles. It skips rows and columns that do not contain numbers.\n",
        "\n",
        "To enable a summary of all the columns, we could add an argument include = \"all\" inside\n",
        "the describe function bracket: \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# dataframe.describe(include=\"all\")\n",
        "```\n",
        "\n",
        "Another method you can use to check your dataset is the dataframe.info function. This function shows the top 30 rows and bottom 30 rows of the dataframe.\n",
        "\n",
        "\n",
        "```\n",
        "# df.info()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "JhC01dhS2m8H"
      }
    }
  ]
}