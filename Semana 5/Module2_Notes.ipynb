{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PosgradoMNA/actividades-de-aprendizaje-SinaiAvalos/blob/main/Semana%205/Module2_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Sinaí Avalos Rivera   A01730466*\n",
        "\n",
        "# **Module 2 - Data Wrangling**\n",
        "\n"
      ],
      "metadata": {
        "id": "GOY-ghXbf3n6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PRE-PROCESSING DATA IN PYTHON**"
      ],
      "metadata": {
        "id": "Kxgu6TxygNti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing is a necessary step in data\n",
        "analysis. It is the process of converting or mapping data from one “raw” form into another\n",
        "format to make it ready for further analysis.\n",
        "\n",
        "Data normalization: Different columns of numerical data may have very different ranges, and direct comparison is often not meaningful. Normalization is a way to bring all data into a similar range, for more useful comparison. Techniques: centering/scaling.\n",
        "\n",
        "\n",
        "Data binning: Binning creates bigger categories from a set of numerical values. It is particularly useful for comparison between groups of data.\n",
        "\n",
        "Each column is a Panda Series.\n",
        "\n",
        "**Add 1 to each \"symbolling\" entry**:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# df['symboling'] = df[\"symboling\"]+1\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "NR_KimFWloY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEALING WITH MISSING VALUES IN PYTHON**"
      ],
      "metadata": {
        "id": "mtYpzS1RghzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When no data value is stored for a feature for a particular observation, we say this\n",
        "feature has a “missing value”.\n",
        "Usually, missing value in dataset appears as “?”, “N/A”, 0 or just a blank cell.\n",
        "\n",
        "OPTIONS TO DEAL WITH MISSING VALUES:\n",
        "\n",
        "* The first is to check if the person or group that collected the data can go back and find what the actual value should be.\n",
        "* Another possibility is just to remove the data where that missing value is found: \n",
        "Drop the variable, drop the data entry\n",
        "* Replacing data: Replace it with an average (of similar datapoints), replace it by frequency (in this case, one possibility is to try using the mode –the most common), replace it based on other functions\n",
        "* Leave it as missing data\n",
        "\n",
        "How to drop missing values or replace missing values in Python. To remove data that contains missing values, pandas library has a built-in method called\n",
        "‘dropna’:\n",
        "\n",
        "\n",
        "```\n",
        "# dataframes.dropna()\n",
        "```\n",
        "\n",
        "Essentially, with the dropna method, you can choose to drop rows or columns that contain\n",
        "missing values, like NaN. Specify “axis=0” to drop the rows, or “axis=1” to drop the\n",
        "columns that contain the missing values.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# df.dropna(subset=['price'], axis=0, inplace = True)\n",
        "```\n",
        "\n",
        "Setting the argument “inplace” to “true” allows the modification to be done on the\n",
        "dataset directly. “Inplace=True” just writes the result back into the dataframe.\n",
        "\n",
        "Equivalent to:\n",
        "\n",
        "```\n",
        "# df = df.dropna(subset=['price'], axis=0)\n",
        "```\n",
        "\n",
        "This line of code does not change the dataframe, but is a good way to make sure that you are performing the correct operation. To modify the dataframe, you have to set the parameter \"inplace\" equal to true.\n",
        "\n",
        "```\n",
        "# df.dropna(subset=['price'], axis=0)\n",
        "```\n",
        "\n",
        "To replace missing values like NaNs with actual values, pandas library has a built in method\n",
        "called ‘replace’, which can be used to fill in the missing values with the newly\n",
        "calculated values.\n",
        "\n",
        "```\n",
        "# dataframe.replace(missing_value, new_value)\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "# mean =  df[\"normalized-losses\"].mean\n",
        "df[\"normalized-losses\"].replace(np.nan, mean)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "yWVjD6tfm7pK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA FORMATTING IN PYTHON**\n",
        "\n",
        "Data formatting means bringing data into a common standard of expression that allows\n",
        "users to make meaningful comparisons.\n",
        "\n",
        "Converto mpg to L/100km in dataset:\n",
        "\n",
        "```\n",
        "# df[\"city-mpg\"] = 235/df[\"city-mpg\"]\n",
        "df.rename(columns=(\"city-mpg\":\"city-L/1000km\"), inplace=True)\n",
        "```\n",
        "\n",
        "For a number of reasons, including when you import a dataset into Python, the data type\n",
        "may be incorrectly established. It is important for later analysis to explore the feature’s data type and convert them\n",
        "to the correct data types; otherwise, the developed models later on may behave strangely, and totally valid data may end up being treated like missing data.\n",
        "\n",
        "\n",
        "To identify a features data type, in Python we can use the dataframe.dtypes() method and\n",
        "check the datatype of each variable in a dataframe.\n",
        "\n",
        "\n",
        "```\n",
        "# dataframe.dtypes()\n",
        "```\n",
        "\n",
        "\n",
        "Convert data types:\n",
        "\n",
        "\n",
        "```\n",
        "# dataframe.astype()\n",
        "```\n",
        "\n",
        "```\n",
        "# df[\"price\"] = df[\"price\"].astype(\"int\")\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wI3TfSwXqOXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA NORMALIZATION IN PYTHON**\n",
        "\n",
        "We may want to normalize these variables so that the range of the values is consistent.\n",
        "This normalization can make some statistical analyses easier down the road.\n",
        "By making the ranges consistent between variables, normalization enables a fairer comparison\n",
        "between the different features. Making sure they have the same impact, it is also important for computational reasons. By making the ranges consistent between variables, normalization enables a fairer comparison between the different features.\n",
        "\n",
        "\n",
        "To avoid this, we can normalize these two variables into values that range from 0 to 1.\n",
        "\n",
        "After normalization, both variables now have a similar influence on the models we will\n",
        "build later.\n",
        "\n",
        "Ways to normalize data: \n",
        "\n",
        "* The first method, called “simple feature scaling”, just divides each value by the\n",
        "maximum value for that feature.\n",
        "This makes the new values range between 0 and 1.\n",
        "\n",
        "```\n",
        "# df[\"lenght\"] = df[\"lenght\"]/df[\"lenght\"].max()\n",
        "```\n",
        "\n",
        "* The second method, called “Min-Max”, takes each value, X_old, subtracted from the minimum\n",
        "value of that feature, then divides by the range of that feature.\n",
        "Again, the resulting new values range between 0 and 1.\n",
        "\n",
        "```\n",
        "# df[\"lenght\"] = (df[\"lenght\"]-df[\"lenght\"].min())/(df[\"lenght\"].max()-df[\"lenght\"].min()) \n",
        "```\n",
        "\n",
        "*The third method is called “z-score” or “standard score”.\n",
        "In this formula, for each value, you subtract the Mu which is the average of the feature,\n",
        "and then divide by the standard deviation (sigma).\n",
        "The resulting values hover around 0, and typically range between -3 and +3, but can be higher\n",
        "or lower. \n",
        "```\n",
        "# df[\"lenght\"] = (df[\"lenght\"]-df[\"lenght\"].mean())/df[\"lenght\"].std()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "G12vgeXQrtlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BINNING IN PYTHON**\n",
        "\n",
        "Binning is when you group values together into bins. For example, you can bin “age”\n",
        "into [0 to 5], [6 to 10], [11 to 15] and so on.\n",
        "\n",
        "In addition, sometimes we use data binning to group a set of numerical values into a\n",
        "smaller number of bins to have a better understanding of the data distribution.\n",
        "Using binning, we categorize.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# bins = np.linspace(min(df[\"price\"]),max(df[\"price\"]),4)\n",
        "group_names=[\"Low\",\"Medium\",\"High\"]\n",
        "\n",
        "df[\"price-binned\"] = pd.cut(df[\"price\"], bins, labels=group_names, includ_lowest=True)\n",
        "```\n",
        "\n",
        "We use the pandas function ”cut” to segment and sort the data values into bins.\n",
        "You can then use histograms to visualize the distribution of the data after they’ve been\n",
        "divided into bins.\n"
      ],
      "metadata": {
        "id": "IQ_h_ub9_JC7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TURNING CATEGORICAL VARIABLES INTO QUANTITATIVE VARIABLES IN PYTHON**\n",
        "\n",
        "Solution:\n",
        "* Add dummy variables for each unique category\n",
        "* Assign 0 or 1 in each category\n",
        "* In Pandas: \n",
        "```\n",
        "# pd.get_dummies(df['fuel'])\n",
        "```\n"
      ],
      "metadata": {
        "id": "BpHwIWbsB0GL"
      }
    }
  ]
}