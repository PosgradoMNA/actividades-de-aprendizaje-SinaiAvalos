{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment01.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PosgradoMNA/actividades-de-aprendizaje-SinaiAvalos/blob/main/Semana%208/Module5_Notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*SinaÃ­ Avalos Rivera A01730466*\n",
        "\n",
        "\n",
        "# **MODULE 5- - MODEL EVALUATION**\n",
        "\n",
        "\n",
        "\n",
        "Separating data into training and testing sets is an important part of model evaluation.\n",
        "We use the test data to get an idea how our model will perform in the real world.\n",
        "\n",
        "We use a training set to build a model and discover predictive relationships.\n",
        "We then use a testing set to evaluate model performance.\n",
        "\n",
        "Splitting datasets:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# Splits a dataset into training and testing subsets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_data,y_data,test_size=0.3,random_state=0)\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "**Generalization error**\n",
        "\n",
        "Generalization error is a measure of how well our data does at predicting previously unseen\n",
        "data. The error we obtain using our testing data is an approximation of this error.\n",
        "\n",
        "\n",
        "**Cross validation**\n",
        "\n",
        "One of the most common out-of-sample evaluation metrics is cross-validation.\n",
        "In this method, the dataset is split into k-equal groups; each group is referred to\n",
        "as a fold. Some of the folds can be used as a training set, which we use to train the model, and\n",
        "the remaining parts are used as a test set, which we use to test the model.\n",
        "\n",
        "This is repeated until each partition is used for both training and testing.\n",
        "At the end, we use the average results as the estimate of out-of-sample error.\n",
        "The evaluation metric depends on the model.\n",
        "\n",
        "\n",
        "```\n",
        "# Apply cross validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(lr,x_dat,y_data,cv=3)\n",
        "\n",
        "#parameters: lr(type of model - linear regression model or object), cv(number of partitions)\n",
        "\n",
        "```\n",
        "\n",
        "The function returns an array of scores, one for each partition that was chosen as the\n",
        "testing set.\n",
        "\n",
        "We can average the result together to estimate out-of-sample R-squared using the mean function\n",
        "in numpy.\n",
        "\n",
        "\n",
        "```\n",
        "# np.mean(scores)\n",
        "```\n",
        "\n",
        "\n",
        "The cross_val_score() function returns a score value to tell us the cross-validation\n",
        "result.\n",
        "\n",
        "\n",
        "If we want a little more information, to know the actual predicted values supplied by our model before the R squared values are calculated: \n",
        "\n",
        "\n",
        "```\n",
        "# from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "yhat=cross_val_predict(lr2,x_data,y_data,cv=3)\n",
        "\n",
        "```\n",
        "\n",
        "The predictions are stored in an array.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-UwbXPfJ0OiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OVERFITTING, UNDERFITTING AND MODEL SELECTION**\n",
        "\n",
        "\n",
        "**Model selection**\n",
        "\n",
        "The goal of model selection is to determine the order of the polynomial to provide the\n",
        "best estimate of the function y(x).\n",
        "\n",
        "\n",
        "Uunder-fitting, the model is too simple to fit the data.\n",
        "\n",
        "\n",
        "Over-fitting, where the model is too flexible and fits the noise rather than the function.\n",
        "\n",
        "\n",
        "The training error decreases with the order of the polynomial.\n",
        "\n",
        "The test error is a better means of estimating the error of a polynomial. The error decreases\n",
        "till the best order of the polynomial is determined, then the error begins to increase.\n",
        "\n",
        "We select the order that minimizes the test error.\n",
        "\n",
        "If we select the best order of the polynomial, we will still have some errors, if you recall, the original expression for the training points.\n",
        "We see a noise term; this term is one reason for the error: y(x)+noise\n",
        "\n",
        "\n",
        "This noise is random and we can't predict it = irreducible error\n",
        "\n",
        "\n",
        "The closer the R-squared is to 1, the more accurate the model is.\n",
        "Here we see the R-squared is optimal when the order of the polynomial is three.\n",
        "The R-squared drastically decreases when the order is increased to this order(3).\n",
        "\n",
        "\n",
        "* Calculate R-squared:\n",
        "\n",
        "```\n",
        "# Rsqu_test = []\n",
        "\n",
        "order=[1,2,3,4]\n",
        "\n",
        "for n in order:\n",
        "  pr=PolynomialFeatures(degree=n)\n",
        "  x_train_pr=pr.fit_transform(x_train[['horsepower']])\n",
        "  x_test_pr=pr.fit_transform(x_test[['horsepower']])\n",
        "\n",
        "  lr.fit(x_train_pr,y_train)\n",
        "  Rsqu_test.append(lr.score(x_test_pr,y_test)\n",
        "```\n"
      ],
      "metadata": {
        "id": "GY_DAhzUGsn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RIDGE REGRESSION**\n",
        "\n",
        "Ridge regression prevents over-fitting.\n",
        "\n",
        "\n",
        "Ridge regression controls the magnitude of these polynomial coefficients by introducing\n",
        "the parameter alpha. Alpha is a parameter we select before fitting or training the model.\n",
        "\n",
        "\n",
        "As alpha increases, the parameters get smaller.\n",
        "\n",
        "This is most evident for the higher order polynomial features, but alpha must be selected\n",
        "carefully.\n",
        "If alpha is too large, the coefficients will approach zero and under-fit the data.\n",
        "If alpha is zero, the over-fitting is evident.\n",
        "\n",
        "\n",
        "To select alpha ------------> cross-validation\n",
        "\n",
        "\n",
        "To make a prediction using ridge regression:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# from sklearn.linear_model import Ridge\n",
        "RigeModel=ridge(alpha=0,1)\n",
        "RigeModel.fit(X,y)\n",
        "Yhat=RigeModel.predict(X)\n",
        "\n",
        "```\n",
        "\n",
        "To make a prediction, we use the predict method.\n",
        "In order to determine the parameter alpha, we use some data for training.\n",
        "We use a second set called validation data; this is similar to test data, but it is used\n",
        "to select parameters like alpha.\n",
        "We start with a small value of alpha, we train the model, make a prediction using the validation\n",
        "data, then calculate the R squared and store the values.\n",
        "Repeat the value for a larger value of alpha.\n",
        "\n",
        "We train the model again, make a prediction using the validation data, then calculate\n",
        "the R squared and store the values of R squared.\n",
        "\n",
        "\n",
        "We select the value of alpha that maximizes the R squared.\n"
      ],
      "metadata": {
        "id": "xXmHFgB4Mjm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRID SEARCH**\n",
        "\n"
      ],
      "metadata": {
        "id": "h-hB8mrePXBm"
      }
    }
  ]
}